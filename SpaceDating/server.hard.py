#!/usr/bin/env python3

import math
import numpy as np
import scipy as sp
import scipy.interpolate
import sklearn.model_selection as skmodel
import sklearn.preprocessing as skpreprocess



flag = "sigsegv{I_L0v3_Tent4cl3s}"
validationlevel = 0.8

feature_desc = [
    {
        "name": "Taille",
        "type": float
    },
    {
        "name": "Poids",
        "type": float
    },
    {
        "name": "Nombre d'enfants",
        "type": int
    },
    {
        "name": "Nombre de tentacules",
        "type": int
    },
    {
        "name": "Nombre de bras",
        "type": int
    },
    {
        "name": "Nombre de jambes",
        "type": int
    },
    {
        "name": "Nombre de dents moyen",
        "type": int
    },
    {
        "name": "Nombre de branchies",
        "type": int
    },
    {
        "name": "Nombre d'yeux",
        "type": int
    },
    {
        "name": "Nombre d'estomacs",
        "type": int
    }
]
nfeatures = len(feature_desc)

names_states = ['begin', 'end'] + list("ABCDEFGHIJKLMNOPQRSTUVWXYZ")
names_statesidx = dict((s, i) for i, s in enumerate(names_states))
names_transition = np.array(
      [[0.00000000e+00, 0.00000000e+00, 7.62650164e-02, 4.09537677e-02,
        8.11794685e-02, 6.26137605e-02, 5.15107390e-02, 2.18420095e-02,
        3.18529305e-02, 2.43902439e-02, 1.52894066e-02, 7.08045140e-02,
        4.98725883e-02, 8.31816527e-02, 9.31925737e-02, 2.67564616e-02,
        1.18310885e-02, 2.03858755e-02, 2.00218420e-03, 5.35129232e-02,
        7.46268657e-02, 5.29668730e-02, 1.45613396e-03, 2.20240262e-02,
        1.58354569e-02, 1.09210047e-03, 8.91882053e-03, 5.64251911e-03],
       [0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 3.67567568e-01, 8.31600832e-04, 9.14760915e-03,
        2.05821206e-02, 2.16216216e-02, 8.31600832e-03, 1.03950104e-03,
        6.65280665e-03, 1.03950104e-02, 1.95426195e-02, 1.24740125e-03,
        6.23700624e-03, 6.69438669e-02, 3.05613306e-02, 1.70270270e-01,
        1.45530146e-03, 1.87110187e-03, 1.87110187e-03, 1.34303534e-01,
        2.70270270e-02, 3.13929314e-02, 2.09979210e-02, 1.03950104e-02,
        6.65280665e-03, 1.45530146e-03, 1.91268191e-02, 2.49480249e-03],
       [0.00000000e+00, 1.51515152e-02, 8.44155844e-02, 4.97835498e-02,
        0.00000000e+00, 4.32900433e-03, 3.63636364e-01, 0.00000000e+00,
        0.00000000e+00, 2.16450216e-03, 9.95670996e-02, 0.00000000e+00,
        0.00000000e+00, 3.24675325e-02, 0.00000000e+00, 0.00000000e+00,
        5.19480519e-02, 0.00000000e+00, 0.00000000e+00, 2.07792208e-01,
        0.00000000e+00, 2.16450216e-03, 3.89610390e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 4.76190476e-02, 0.00000000e+00],
       [0.00000000e+00, 1.68243954e-02, 1.95583596e-01, 0.00000000e+00,
        4.20609884e-03, 0.00000000e+00, 1.61934805e-01, 0.00000000e+00,
        0.00000000e+00, 1.96635121e-01, 1.18822292e-01, 0.00000000e+00,
        6.72975815e-02, 5.78338591e-02, 0.00000000e+00, 0.00000000e+00,
        1.00946372e-01, 0.00000000e+00, 1.57728707e-02, 2.62881178e-02,
        0.00000000e+00, 8.41219769e-03, 6.30914826e-03, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.31335436e-02, 0.00000000e+00],
       [0.00000000e+00, 1.06643357e-01, 2.84965035e-01, 0.00000000e+00,
        0.00000000e+00, 1.22377622e-02, 1.98426573e-01, 8.74125874e-04,
        7.86713287e-03, 0.00000000e+00, 1.09265734e-01, 0.00000000e+00,
        0.00000000e+00, 3.49650350e-03, 2.62237762e-03, 5.24475524e-03,
        1.13636364e-01, 0.00000000e+00, 0.00000000e+00, 8.39160839e-02,
        7.86713287e-03, 0.00000000e+00, 1.13636364e-02, 0.00000000e+00,
        1.04895105e-02, 0.00000000e+00, 4.10839161e-02, 0.00000000e+00],
       [0.00000000e+00, 2.84476534e-01, 3.32129964e-02, 8.66425993e-03,
        6.97954272e-03, 2.40673887e-02, 3.08062575e-02, 6.25752106e-03,
        6.97954272e-03, 4.81347774e-04, 1.34777377e-02, 9.62695548e-04,
        3.36943442e-03, 1.53790614e-01, 1.73285199e-02, 1.13838748e-01,
        1.61251504e-02, 5.53549940e-03, 4.81347774e-04, 1.12394705e-01,
        4.04332130e-02, 6.25752106e-02, 5.05415162e-03, 1.46811071e-02,
        4.57280385e-03, 3.36943442e-03, 2.83995187e-02, 1.68471721e-03],
       [0.00000000e+00, 2.63157895e-02, 1.62280702e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.49122807e-01, 9.21052632e-02,
        0.00000000e+00, 0.00000000e+00, 8.33333333e-02, 0.00000000e+00,
        0.00000000e+00, 9.64912281e-02, 0.00000000e+00, 0.00000000e+00,
        7.89473684e-02, 0.00000000e+00, 0.00000000e+00, 2.76315789e-01,
        0.00000000e+00, 8.77192982e-03, 2.19298246e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 4.38596491e-03, 0.00000000e+00],
       [0.00000000e+00, 1.23110151e-01, 1.64146868e-01, 0.00000000e+00,
        0.00000000e+00, 1.07991361e-02, 2.67818575e-01, 0.00000000e+00,
        1.29589633e-02, 3.45572354e-02, 1.31749460e-01, 0.00000000e+00,
        0.00000000e+00, 4.75161987e-02, 2.15982721e-03, 1.94384449e-02,
        4.10367171e-02, 0.00000000e+00, 0.00000000e+00, 7.34341253e-02,
        0.00000000e+00, 0.00000000e+00, 5.39956803e-02, 0.00000000e+00,
        1.29589633e-02, 0.00000000e+00, 4.31965443e-03, 0.00000000e+00],
       [0.00000000e+00, 1.14488349e-01, 3.88044580e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.20871327e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 9.32117528e-02, 0.00000000e+00,
        0.00000000e+00, 1.62107396e-02, 2.02634245e-03, 2.02634245e-02,
        5.67375887e-02, 0.00000000e+00, 0.00000000e+00, 3.34346505e-02,
        1.01317123e-03, 5.06585613e-03, 2.73556231e-02, 0.00000000e+00,
        1.01317123e-03, 0.00000000e+00, 2.02634245e-02, 0.00000000e+00],
       [0.00000000e+00, 6.75482487e-02, 1.22944961e-01, 4.28877770e-03,
        6.29020729e-02, 2.85918513e-02, 1.52966405e-01, 6.07576841e-03,
        1.25089350e-02, 0.00000000e+00, 0.00000000e+00, 1.07219442e-03,
        2.18012866e-02, 8.43459614e-02, 1.67977127e-02, 1.75482487e-01,
        2.25160829e-02, 2.85918513e-03, 3.93137956e-03, 2.93066476e-02,
        1.08291637e-01, 5.21801287e-02, 3.57398142e-03, 1.00071480e-02,
        0.00000000e+00, 1.42959257e-03, 7.14796283e-04, 7.86275911e-03],
       [0.00000000e+00, 0.00000000e+00, 3.37349398e-01, 0.00000000e+00,
        2.40963855e-03, 0.00000000e+00, 2.40963855e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.65060241e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.67469880e-01, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.25301205e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 8.61723447e-02, 3.18637275e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.94388778e-01, 0.00000000e+00,
        0.00000000e+00, 4.00801603e-03, 1.74348697e-01, 0.00000000e+00,
        8.01603206e-03, 1.00200401e-02, 0.00000000e+00, 0.00000000e+00,
        9.61923848e-02, 0.00000000e+00, 2.00400802e-03, 5.81162325e-02,
        4.00801603e-03, 0.00000000e+00, 8.01603206e-03, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.60721443e-02, 0.00000000e+00],
       [0.00000000e+00, 9.99611046e-02, 1.71139634e-01, 1.05017503e-02,
        1.94476857e-03, 2.87825749e-02, 1.92143135e-01, 7.39012058e-03,
        7.77907429e-04, 7.77907429e-04, 1.67639051e-01, 0.00000000e+00,
        1.55581486e-03, 1.21353559e-01, 1.12796577e-02, 1.94476857e-03,
        6.84558538e-02, 3.88953715e-03, 0.00000000e+00, 1.16686114e-03,
        7.00116686e-03, 7.77907429e-03, 2.13924543e-02, 1.32244263e-02,
        7.77907429e-04, 0.00000000e+00, 5.87320109e-02, 3.88953715e-04],
       [0.00000000e+00, 3.28685259e-02, 4.17330677e-01, 2.09163347e-02,
        1.99203187e-03, 0.00000000e+00, 1.61354582e-01, 0.00000000e+00,
        9.96015936e-04, 0.00000000e+00, 2.05179283e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.68525896e-02, 9.96015936e-04,
        6.77290837e-02, 5.97609562e-03, 0.00000000e+00, 9.96015936e-04,
        9.96015936e-04, 0.00000000e+00, 1.19521912e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.38645418e-02, 0.00000000e+00],
       [0.00000000e+00, 2.11820977e-01, 1.70140075e-01, 0.00000000e+00,
        2.35736249e-02, 8.47283908e-02, 1.66723608e-01, 1.70823369e-03,
        2.93816194e-02, 2.73317390e-03, 1.02494021e-01, 3.07482064e-03,
        3.07482064e-03, 6.83293475e-04, 6.83293475e-04, 9.77109669e-02,
        2.73317390e-02, 0.00000000e+00, 3.41646737e-04, 2.73317390e-03,
        6.49128801e-03, 3.17731466e-02, 4.78305432e-03, 6.83293475e-04,
        1.02494021e-03, 0.00000000e+00, 2.28903314e-02, 3.41646737e-03],
       [0.00000000e+00, 1.29928895e-01, 9.69618617e-03, 2.58564964e-02,
        1.09890110e-02, 3.16742081e-02, 1.61603103e-02, 3.87847447e-03,
        3.87847447e-03, 1.55138979e-02, 1.22818358e-02, 0.00000000e+00,
        9.04977376e-03, 9.89010989e-02, 3.94311571e-02, 2.41758242e-01,
        9.69618617e-03, 8.40336134e-03, 0.00000000e+00, 1.81641888e-01,
        6.52876535e-02, 2.13316096e-02, 2.13316096e-02, 1.03425986e-02,
        4.52488688e-03, 4.52488688e-03, 1.87459599e-02, 5.17129929e-03],
       [0.00000000e+00, 1.50753769e-02, 2.76381910e-01, 0.00000000e+00,
        5.02512563e-03, 0.00000000e+00, 2.06030151e-01, 0.00000000e+00,
        0.00000000e+00, 2.61306533e-01, 7.53768844e-02, 0.00000000e+00,
        0.00000000e+00, 1.50753769e-02, 0.00000000e+00, 0.00000000e+00,
        5.52763819e-02, 1.00502513e-02, 0.00000000e+00, 6.53266332e-02,
        0.00000000e+00, 1.00502513e-02, 5.02512563e-03, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.78571429e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 9.82142857e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 4.45344130e-02, 1.42914980e-01, 5.26315789e-03,
        1.41700405e-02, 2.63157895e-02, 1.33198381e-01, 8.09716599e-04,
        2.46963563e-02, 3.64372470e-03, 2.14574899e-01, 8.09716599e-04,
        4.04858300e-03, 5.95141700e-02, 2.18623482e-02, 2.87449393e-02,
        8.94736842e-02, 4.04858300e-04, 2.02429150e-03, 4.81781377e-02,
        1.05263158e-02, 4.17004049e-02, 1.86234818e-02, 6.07287449e-03,
        1.61943320e-03, 4.04858300e-04, 5.58704453e-02, 0.00000000e+00],
       [0.00000000e+00, 1.22198120e-01, 1.43890094e-01, 7.23065799e-04,
        1.59074476e-02, 0.00000000e+00, 1.00506146e-01, 0.00000000e+00,
        0.00000000e+00, 2.19088937e-01, 7.30296457e-02, 0.00000000e+00,
        7.23065799e-04, 9.39985539e-03, 5.78452639e-03, 0.00000000e+00,
        4.12147505e-02, 6.50759219e-03, 7.23065799e-04, 1.44613160e-03,
        6.57989877e-02, 1.39551699e-01, 3.47071584e-02, 1.44613160e-03,
        1.44613160e-03, 0.00000000e+00, 1.59074476e-02, 0.00000000e+00],
       [0.00000000e+00, 6.96909928e-02, 2.13675214e-01, 0.00000000e+00,
        3.94477318e-03, 0.00000000e+00, 1.43984221e-01, 0.00000000e+00,
        0.00000000e+00, 1.27547666e-01, 1.09796187e-01, 0.00000000e+00,
        0.00000000e+00, 7.88954635e-03, 0.00000000e+00, 7.88954635e-03,
        9.07297830e-02, 0.00000000e+00, 0.00000000e+00, 5.12820513e-02,
        4.60223537e-03, 1.26890204e-01, 9.20447074e-03, 0.00000000e+00,
        3.94477318e-03, 0.00000000e+00, 2.62984878e-02, 2.62984878e-03],
       [0.00000000e+00, 3.21489002e-02, 5.58375635e-02, 2.03045685e-02,
        4.23011844e-02, 7.61421320e-02, 1.01522843e-01, 8.46023689e-03,
        3.55329949e-02, 0.00000000e+00, 6.26057530e-02, 0.00000000e+00,
        2.19966159e-02, 1.11675127e-01, 2.03045685e-02, 1.03214890e-01,
        6.76818951e-03, 1.01522843e-02, 0.00000000e+00, 1.20135364e-01,
        1.20135364e-01, 1.86125212e-02, 0.00000000e+00, 3.38409475e-03,
        0.00000000e+00, 0.00000000e+00, 8.46023689e-03, 2.03045685e-02],
       [0.00000000e+00, 2.98507463e-03, 2.41791045e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.19402985e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.43283582e-01, 0.00000000e+00,
        2.98507463e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        8.35820896e-02, 0.00000000e+00, 0.00000000e+00, 2.98507463e-03,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.98507463e-03, 0.00000000e+00],
       [0.00000000e+00, 4.91803279e-02, 2.62295082e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.53005464e-01, 0.00000000e+00,
        0.00000000e+00, 1.63934426e-02, 3.11475410e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 5.46448087e-03, 1.03825137e-01,
        4.37158470e-02, 0.00000000e+00, 0.00000000e+00, 1.09289617e-02,
        0.00000000e+00, 5.46448087e-03, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.82513661e-02, 0.00000000e+00],
       [0.00000000e+00, 1.79487179e-01, 2.82051282e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.56410256e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 3.58974359e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        2.56410256e-02, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,
        0.00000000e+00, 5.12820513e-02, 2.56410256e-02, 0.00000000e+00,
        2.56410256e-02, 0.00000000e+00, 2.56410256e-02, 0.00000000e+00],
       [0.00000000e+00, 4.98316498e-01, 5.94837262e-02, 6.73400673e-03,
        1.57126824e-02, 1.57126824e-02, 4.26487093e-02, 1.12233446e-03,
        0.00000000e+00, 0.00000000e+00, 4.48933782e-03, 2.24466891e-03,
        0.00000000e+00, 7.74410774e-02, 1.57126824e-02, 1.49270483e-01,
        2.46913580e-02, 0.00000000e+00, 0.00000000e+00, 2.80583614e-02,
        2.91806958e-02, 6.73400673e-03, 1.68350168e-02, 4.48933782e-03,
        1.12233446e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],
       [0.00000000e+00, 1.07142857e-01, 2.58928571e-01, 1.78571429e-02,
        0.00000000e+00, 0.00000000e+00, 2.05357143e-01, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 1.16071429e-01, 0.00000000e+00,
        0.00000000e+00, 8.92857143e-03, 1.78571429e-02, 0.00000000e+00,
        1.25000000e-01, 0.00000000e+00, 0.00000000e+00, 8.92857143e-03,
        0.00000000e+00, 0.00000000e+00, 6.25000000e-02, 0.00000000e+00,
        0.00000000e+00, 0.00000000e+00, 2.67857143e-02, 4.46428571e-02]])


def gen_name_unfiltered():
    seq = []
    state = 'begin'
    while state != 'end':
        prob = names_transition[names_statesidx[state]]
        state = np.random.choice(names_states, p=prob)
        seq.append(state)

    return "".join(seq[:-1]).capitalize()



def gen_name():
    name = gen_name_unfiltered()
    while len(name) <= 2:
        name = gen_name_unfiltered()

    return name



def gen_population(popsize):
    # Generate some data following a normal distribution with more or less variance
    ngauss = np.random.randint(nfeatures * 3/4, nfeatures + 1)
    gauss = np.random.randn(popsize, ngauss)
    variance = np.logspace(0, -2, ngauss)
    gauss *= np.sqrt(variance)

    # Generate a linear combination of the random variables in order to
    # generate some correlated features with mean 0 and variance 1.
    comb = np.random.rand(ngauss, nfeatures) * 2 - 1
    idx = np.arange(ngauss)
    comb[idx, np.random.permutation(ngauss)] *= 5
    combvar = variance.dot(comb**2)
    comb /= np.sqrt(combvar)

    pop = gauss.dot(comb)

    # Offset the mean and variance of the features
    featstds = np.random.rand(nfeatures) * 50 + 1
    pop *= featstds
    featavgs = (np.random.rand(nfeatures) + 1) * -np.min(pop, axis=0)
    pop += featavgs

    # Round both integers and float features
    intmask = np.array([f["type"] == int for f in feature_desc])
    pop[:, intmask] = np.around(pop[:, intmask])
    pop[:, ~intmask] = np.around(pop[:, ~intmask], 2)
    return pop, featstds, featavgs



def choose_coef(pop, pickyness):
    coef = np.random.randn(pop.shape[1])

    y = pop.dot(coef)
    y.sort()
    x = np.linspace(0, 1, y.shape[0])
    f = sp.interpolate.interp1d(x, y, assume_sorted=True)
    bias = -f(pickyness)

    return coef, bias



def print_profile(profile, like=None):
    print("Profil de", gen_name())
    for feature, v in zip(feature_desc, profile):
        v = feature["type"](v)
        print("\t%s: %s" % (feature["name"], v))

    if like is not None:
        print("\tlike:", "oui" if like else "non")

    print("")



def main():
    pop, popstd, popavg = gen_population(2000)
    poly = skpreprocess.PolynomialFeatures(degree=2, include_bias=False)

    # polypop gets centered and standardized so that choose_coef does something
    # interesting.
    polypop = poly.fit_transform((pop - popavg) / popstd)

    while True:
        pickyness = np.random.rand()
        coef, bias = choose_coef(polypop, pickyness)
        likescore = polypop.dot(coef) + bias
        likescore += np.random.randn(likescore.shape[0])
        likes = (likescore > 0)

        test_size = 0.25
        poptrain, poptest, likestrain, likestest = skmodel.train_test_split(pop, likes, test_size=test_size)

        mincorrectlike = (1 - pickyness) * len(likestest) * validationlevel
        mincorrectdiscard = pickyness * len(likestest) * validationlevel
        mincorrectlike = min(math.ceil(mincorrectlike), likestest.sum())
        mincorrectdiscard = min(math.ceil(mincorrectdiscard), (~likestest).sum())

        # There must be at least two of each
        if mincorrectlike >= 2 and mincorrectdiscard >= 2:
            break


    username = gen_name()
    print("L'utilisateur %s a donné son avis sur les %d profils suivants" % (username, len(poptrain)))

    for n, (profile, like) in enumerate(zip(poptrain, likestrain), 1):
        print_profile(profile, like)



    print("%s va-t-il liker ou écarter ces %d profils?" % (username, len(poptest)))
    print("Vous devez correctement identifier au moins %d profils que "
            "l'utilisateur va liker et %d qu'il va écarter."
            % (mincorrectlike, mincorrectdiscard))

    correctlike = 0
    correctdiscard = 0

    for n, (profile, like) in enumerate(zip(poptest, likestest), len(poptrain) + 1):
        print_profile(profile)

        while True:
            ans = input("%s va-t-il liker ce profile ? [O/N] " % username)
            ans = ans.upper()
            if ans and ans in "ON":
                break

        if ans == "O":
            if like:
                correctlike += 1
                print("Correct, %s a liké ce profil" % username)
            else:
                print("Faux, %s a écarté ce profil" % username)
        else:
            if like:
                print("Faux, %s aurait aimé ce profil" % username)
            else:
                correctdiscard += 1
                print("Correct, %s aurait écarté ce profil" % username)

    if correctlike >= mincorrectlike and correctdiscard >= mincorrectdiscard:
        print("Vous avez %d/%d (%.2f%%) bonnes prédictions positives et "
                "%d/%d (%.2f%%) bonnes prédictions négatives." %
                (correctlike, mincorrectlike, 100 * correctlike / mincorrectlike,
                correctdiscard, mincorrectdiscard, 100 * correctdiscard / mincorrectdiscard))
        print("Trouvez-vous ce flag à votre goût ?")
        print(flag)
    else:
        if correctlike < mincorrectlike:
            print("Désolé, vous n'avez que %d bonne prédictions positives "
                    "sur les %d requises." % (correctlike, mincorrectlike))
        if correctdiscard < mincorrectdiscard:
            print("Désolé, vous n'avez que %d bonne prédictions négatives "
                    "sur les %d requises." % (correctdiscard, mincorrectdiscard))



if __name__ == '__main__':
    main()
